"use strict";(self.webpackChunkflowtorch=self.webpackChunkflowtorch||[]).push([[4796],{7985:(e,a,s)=>{s.r(a),s.d(a,{contentTitle:()=>r,default:()=>u,frontMatter:()=>c,metadata:()=>p,toc:()=>h});var t=s(7462),n=(s(7294),s(3905)),o=s(2814),l=s(1436),d=s(1032),i=(s(8666),s(2520)),m=(s(84),s(7868));const c={id:"flowtorch.distributions.nealsfunnel",sidebar_label:"NealsFunnel"},r=void 0,p={unversionedId:"api/flowtorch.distributions.nealsfunnel",id:"api/flowtorch.distributions.nealsfunnel",isDocsHomePage:!1,title:"flowtorch.distributions.nealsfunnel",description:"flowtorch  distributions  NealsFunnel",source:"@site/docs/api/flowtorch.distributions.nealsfunnel.mdx",sourceDirName:"api",slug:"/api/flowtorch.distributions.nealsfunnel",permalink:"/api/flowtorch.distributions.nealsfunnel",editUrl:"https://github.com/facebookincubator/flowtorch/edit/main/website/docs/api/flowtorch.distributions.nealsfunnel.mdx",tags:[],version:"current",frontMatter:{id:"flowtorch.distributions.nealsfunnel",sidebar_label:"NealsFunnel"},sidebar:"apiSidebar",previous:{title:"Flow",permalink:"/api/flowtorch.distributions.flow"},next:{title:"Overview",permalink:"/api/flowtorch.docs"}},h=[{value:'<span className="doc-symbol-name">flowtorch.distributions.NealsFunnel</span>',id:"class",children:[{value:'<span className="doc-symbol-name">__init__</span>',id:"--init--",children:[],level:3},{value:'<span className="doc-symbol-name">cdf</span>',id:"cdf",children:[],level:3},{value:'<span className="doc-symbol-name">entropy</span>',id:"entropy",children:[],level:3},{value:'<span className="doc-symbol-name">enumerate_support</span>',id:"enumerate-support",children:[],level:3},{value:'<span className="doc-symbol-name">expand</span>',id:"expand",children:[],level:3},{value:'<span className="doc-symbol-name">icdf</span>',id:"icdf",children:[],level:3},{value:'<span className="doc-symbol-name">log_prob</span>',id:"log-prob",children:[],level:3},{value:'<span className="doc-symbol-name">perplexity</span>',id:"perplexity",children:[],level:3},{value:'<span className="doc-symbol-name">rsample</span>',id:"rsample",children:[],level:3},{value:'<span className="doc-symbol-name">sample</span>',id:"sample",children:[],level:3},{value:'<span className="doc-symbol-name">sample_n</span>',id:"sample-n",children:[],level:3},{value:'<span className="doc-symbol-name">set_default_validate_args</span>',id:"set-default-validate-args",children:[],level:3}],level:2}],b={toc:h};function u(e){let{components:a,...s}=e;return(0,n.kt)("wrapper",(0,t.Z)({},b,s,{components:a,mdxType:"MDXLayout"}),(0,n.kt)(m.Z,{url:"https://github.com/facebookincubator/flowtorch/blob/main/flowtorch/distributions/neals_funnel.py",mdxType:"PythonNavbar"},(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"/api/flowtorch"},"flowtorch")," ",(0,n.kt)(o.G,{icon:l.cLY,size:"sm",mdxType:"FontAwesomeIcon"})," ",(0,n.kt)("a",{parentName:"p",href:"/api/flowtorch.distributions"},"distributions")," ",(0,n.kt)(o.G,{icon:l.cLY,size:"sm",mdxType:"FontAwesomeIcon"})," ",(0,n.kt)("em",{parentName:"p"},"NealsFunnel"))),(0,n.kt)(d.Z,{mdxType:"PythonClass"},(0,n.kt)("div",{className:"doc-class-row"},(0,n.kt)("div",{className:"doc-class-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"class")),(0,n.kt)("div",{className:"doc-class-signature"},(0,n.kt)("h2",{id:"class"},(0,n.kt)("span",{className:"doc-symbol-name"},"flowtorch.distributions.NealsFunnel")),(0,n.kt)("span",{className:"doc-inherits-from"},"Inherits from: ",(0,n.kt)("span",{className:"doc-symbol-name"},"torch.distributions.distribution.Distribution"))))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nNeal's funnel.\np(x,y) = N(y|0,3) N(x|0,exp(y/2))\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"--init--"},(0,n.kt)("span",{className:"doc-symbol-name"},"_","_","init","_","_")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, validate_args: Any = None) -> None")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"<empty docstring>\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"cdf"},(0,n.kt)("span",{className:"doc-symbol-name"},"cdf")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, value)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nReturns the cumulative density/mass function evaluated at\n`value`.\n\nArgs:\nvalue (Tensor):\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"entropy"},(0,n.kt)("span",{className:"doc-symbol-name"},"entropy")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nReturns entropy of distribution, batched over batch_shape.\n\nReturns:\nTensor of shape batch_shape.\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"enumerate-support"},(0,n.kt)("span",{className:"doc-symbol-name"},"enumerate","_","support")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, expand=True)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nReturns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.\n\nArgs:\nexpand (bool): whether to expand the support over the\nbatch dims to match the distribution's `batch_shape`.\n\nReturns:\nTensor iterating over dimension 0.\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"expand"},(0,n.kt)("span",{className:"doc-symbol-name"},"expand")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, batch_shape, _instance=None)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nReturns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.\n\nArgs:\nbatch_shape (torch.Size): the desired expanded size.\n_instance: new instance provided by subclasses that\nneed to override `.expand`.\n\nReturns:\nNew distribution instance with batch dimensions expanded to\n`batch_size`.\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"icdf"},(0,n.kt)("span",{className:"doc-symbol-name"},"icdf")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, value)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nReturns the inverse cumulative density/mass function evaluated at\n`value`.\n\nArgs:\nvalue (Tensor):\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"log-prob"},(0,n.kt)("span",{className:"doc-symbol-name"},"log","_","prob")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, value: torch.Tensor, context: Union[torch.Tensor, NoneType] = None) -> torch.Tensor")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"<empty docstring>\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"perplexity"},(0,n.kt)("span",{className:"doc-symbol-name"},"perplexity")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nReturns perplexity of distribution, batched over batch_shape.\n\nReturns:\nTensor of shape batch_shape.\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"rsample"},(0,n.kt)("span",{className:"doc-symbol-name"},"rsample")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, sample_shape: Union[torch.Tensor, torch.Size] = None, context: Union[torch.Tensor, NoneType] = None) -> torch.Tensor")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"<empty docstring>\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"sample"},(0,n.kt)("span",{className:"doc-symbol-name"},"sample")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, sample_shape=torch.Size([]))")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nGenerates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"sample-n"},(0,n.kt)("span",{className:"doc-symbol-name"},"sample","_","n")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(self, n)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nGenerates n samples or n batches of samples if the distribution\nparameters are batched.\n\n")),(0,n.kt)(i.Z,{mdxType:"PythonMethod"},(0,n.kt)("div",{className:"doc-method-row"},(0,n.kt)("div",{className:"doc-method-label"},(0,n.kt)("span",{className:"doc-symbol-label"},"member")),(0,n.kt)("div",{className:"doc-method-signature"},(0,n.kt)("h3",{id:"set-default-validate-args"},(0,n.kt)("span",{className:"doc-symbol-name"},"set","_","default","_","validate","_","args")),(0,n.kt)("span",{className:"doc-symbol-signature"},"(value)")))),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\nSets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.\n\nArgs:\nvalue (bool): Whether to enable validation.\n\n")))}u.isMDXComponent=!0}}]);