{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Bijections\n",
    "## Background\n",
    "The fundamental idea of normalizing flows also applies to multivariate random variables, and this is where its value is clearly seen - *representing complex high-dimensional distributions*. In this case, a simple multivariate source of noise, for example a standard i.i.d. normal distribution, $X\\sim\\mathcal{N}(\\mathbf{0},I_{D\\times D})$, is passed through a vector-valued bijection, $g:\\mathbb{R}^D\\rightarrow\\mathbb{R}^D$, to produce the more complex transformed variable $Y=g(X)$.\n",
    "\n",
    "Sampling $Y$ is again trivial and involves evaluation of the forward pass of $g$. We can score $Y$ using the multivariate substitution rule of integral calculus,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "     \\mathbb{E}_{p_X(\\cdot)}\\left[f(X)\\right] &= \\int_{\\text{supp}(X)}f(\\mathbf{x})p_X(\\mathbf{x})d\\mathbf{x}\\\\\n",
    "     &= \\int_{\\text{supp}(Y)}f(g^{-1}(\\mathbf{y}))p_X(g^{-1}(\\mathbf{y}))\\det\\left|\\frac{d\\mathbf{x}}{d\\mathbf{y}}\\right|d\\mathbf{y}\\\\\n",
    "     &= \\mathbb{E}_{p_Y(\\cdot)}\\left[f(g^{-1}(Y))\\right],\n",
    " \\end{aligned}\n",
    "$$\n",
    "\n",
    "where $d\\mathbf{x}/d\\mathbf{y}$ denotes the Jacobian matrix of $g^{-1}(\\mathbf{y})$. Equating the last two lines we get,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "     \\log(p_Y(y)) &= \\log(p_X(g^{-1}(y)))+\\log\\left(\\det\\left|\\frac{d\\mathbf{x}}{d\\mathbf{y}}\\right|\\right)\\\\\n",
    "     &= \\log(p_X(g^{-1}(y)))-\\log\\left(\\det\\left|\\frac{d\\mathbf{y}}{d\\mathbf{x}}\\right|\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Inituitively, this equation says that the density of $Y$ is equal to the density at the corresponding point in $X$ plus a term that corrects for the warp in volume around an infinitesimally small volume around $Y$ caused by the transformation. For instance, in $2$-dimensions, the geometric interpretation of the absolute value of the determinant of a Jacobian is that it represents the area of a parallelogram with edges defined by the columns of the Jacobian. In $n$-dimensions, the geometric interpretation of the absolute value of the determinant Jacobian is that is represents the hyper-volume of a parallelepiped with $n$ edges defined by the columns of the Jacobian (see a calculus reference such as [Stewart, 2015](https://www.amazon.com/gp/product/B00YHKU50E) for more details).\n",
    "\n",
    "Similar to the univariate case, we can compose such bijective transformations to produce even more complex distributions. By an inductive argument, if we have $L$ transforms $g_{(0)}, g_{(1)},\\ldots,g_{(L-1)}$, then the log-density of the transformed variable $Y=(g_{(0)}\\circ g_{(1)}\\circ\\cdots\\circ g_{(L-1)})(X)$ is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "     \\log(p_Y(y)) &= \\log\\left(p_X\\left(\\left(g_{(L-1)}^{-1}\\circ\\cdots\\circ g_{(0)}^{-1}\\right)\\left(y\\right)\\right)\\right)+\\sum^{L-1}_{l=0}\\log\\left(\\left|\\frac{dg^{-1}_{(l)}(y_{(l)})}{dy'}\\right|\\right),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where we've defined $y_{(0)}=x$, $y_{(L-1)}=y$ for convenience of notation.\n",
    "\n",
    "The main challenge is in designing parametrizable multivariate bijections that have closed form expressions for both $g$ and $g^{-1}$, a tractable Jacobian whose calculation scales with $O(D)$ or $O(1)$ rather than $O(D^3)$, and can express a flexible class of functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate `Bijector`s\n",
    "In this section, we show how to use [`B.SplineAutoregressive`](https://flowtorch.ai/api/flowtorch.bijectors.splineautoregressive) to learn the bivariate toy distribution from our running example. Making a simple change we can represent bivariate distributions of the form, $p(x_1,x_2)=p(x_1)p(x_2|x_1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dist_x = torch.distributions.Independent(\n",
    "  torch.distributions.Normal(torch.zeros(2), torch.ones(2)), \n",
    "  1\n",
    ")\n",
    "bijector = bij.SplineAutoregressive()\n",
    "dist_y = dist.Flow(dist_x, bijector)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a889874aef137a58c8f92e3ed6912ec441c66e3cc8f3752c91ed486cb306b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
