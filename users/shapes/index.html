<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.70">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><title data-react-helmet="true">Shapes | FlowTorch</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Shapes | FlowTorch"><meta data-react-helmet="true" name="description" content="One of the advantages of using FlowTorch is that we have carefully thought out how shape information is propagated from the base distribution through the sequence of bijective transforms. Before we explain how shapes are handled in FlowTorch, let us revisit the shape conventions shared across PyTorch and TensorFlow."><meta data-react-helmet="true" property="og:description" content="One of the advantages of using FlowTorch is that we have carefully thought out how shape information is propagated from the base distribution through the sequence of bijective transforms. Before we explain how shapes are handled in FlowTorch, let us revisit the shape conventions shared across PyTorch and TensorFlow."><meta data-react-helmet="true" property="og:url" content="https://flowtorch.ai/users/shapes"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.png"><link data-react-helmet="true" rel="canonical" href="https://flowtorch.ai/users/shapes"><link rel="stylesheet" href="/styles.dee88544.css">
<link rel="preload" href="/styles.6ecebfe1.js" as="script">
<link rel="preload" href="/runtime~main.c1f695ac.js" as="script">
<link rel="preload" href="/main.364a143d.js" as="script">
<link rel="preload" href="/1.ec4b77b1.js" as="script">
<link rel="preload" href="/2.4c431536.js" as="script">
<link rel="preload" href="/79.187d9098.js" as="script">
<link rel="preload" href="/81.b7c78fc7.js" as="script">
<link rel="preload" href="/935f2afb.ab61ba57.js" as="script">
<link rel="preload" href="/17896441.ae2496ef.js" as="script">
<link rel="preload" href="/88d676a5.60aec92c.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_11B0">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="FlowTorch Logo" class="themedImage_YANc themedImage--light_3CMI navbar__logo"><img src="/img/logo.svg" alt="FlowTorch Logo" class="themedImage_YANc themedImage--dark_3ARp navbar__logo"><strong class="navbar__title">FlowTorch</strong></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/users">Users</a><a class="navbar__item navbar__link" href="/dev">Developers</a><a class="navbar__item navbar__link" href="/api">Reference</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebookincubator/flowtorch/discussions" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Discussions</a><a href="https://github.com/facebookincubator/flowtorch/releases" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Releases</a><a href="https://github.com/facebookincubator/flowtorch" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2N3Q"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_3NWk">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_3NWk">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="FlowTorch Logo" class="themedImage_YANc themedImage--light_3CMI navbar__logo"><img src="/img/logo.svg" alt="FlowTorch Logo" class="themedImage_YANc themedImage--dark_3ARp navbar__logo"><strong class="navbar__title">FlowTorch</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/users">Users</a></li><li class="menu__list-item"><a class="menu__link" href="/dev">Developers</a></li><li class="menu__list-item"><a class="menu__link" href="/api">Reference</a></li><li class="menu__list-item"><a href="https://github.com/facebookincubator/flowtorch/discussions" target="_blank" rel="noopener noreferrer" class="menu__link">Discussions</a></li><li class="menu__list-item"><a href="https://github.com/facebookincubator/flowtorch/releases" target="_blank" rel="noopener noreferrer" class="menu__link">Releases</a></li><li class="menu__list-item"><a href="https://github.com/facebookincubator/flowtorch" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_vMrn"><div class="docSidebarContainer_3Ak5" role="complementary"><div class="sidebar_3gvy"><div class="menu menu--responsive thin-scrollbar menu_1yIk"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_1CUI" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Getting Started</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users">Introduction</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/installation">Installation</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/start">Your First Flow</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Normalizing Flows</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/univariate">Univariate Bijections</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/multivariate">Multivariate Bijections</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/conditional">Conditional Bijections</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/methods">Table of Methods</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Basic Concepts</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/users/shapes">Shapes</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/constraints">Constraints</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/bijectors">Bijectors</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/parameters">Parameters</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/transformed_distributions">Transformed Distributions</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/conditioning">Conditioning</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/composing">Composing Bijectors</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/gpu_support">GPU Support</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/users/serialization">Serialization</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Advanced Topics</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/caching">Caching</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/initialization">Initialization</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/structure">Structured Representations</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/users/torchscript">TorchScript</a></li></ul></li></ul></div></div></div><main class="docMainContainer_2iGs"><div class="container padding-vert--lg docItemWrapper_1bxp"><div class="row"><div class="col docItemCol_U38p"><div class="docItemContainer_a7m4"><article><header><h1 class="docTitle_Oumm">Shapes</h1></header><div class="markdown"><p>One of the advantages of using FlowTorch is that we have carefully thought out how shape information is propagated from the base distribution through the sequence of bijective transforms. Before we explain how shapes are handled in FlowTorch, let us revisit the shape conventions shared across PyTorch and TensorFlow.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="shape-conventions"></a>Shape Conventions<a class="hash-link" href="#shape-conventions" title="Direct link to heading">#</a></h2><p>FlowTorch shares the shape conventions of PyTorch&#x27;s <a href="https://pytorch.org/docs/stable/distributions.html#distribution" target="_blank" rel="noopener noreferrer"><code>torch.distributions.Distribution</code></a> and TensorFlow&#x27;s <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" target="_blank" rel="noopener noreferrer"><code>tfp.distributions.Distribution</code></a> for representing random distributions. In these conventions, the shape of a tensor sampled from a random distribution is divided into three parts: the <em>sample shape</em>, the <em>batch shape</em>, and the <em>event shape</em>.</p><p>As described in the <a href="https://www.tensorflow.org/probability/examples/Understanding_TensorFlow_Distributions_Shapes#basics" target="_blank" rel="noopener noreferrer">TensorFlow documentation</a>,</p><ul><li>Event shape describes the shape of a single draw from the distribution, which may or may not be dependent across dimensions.</li><li>Batch shape describes independent, not identically distributed draws, that is, a &quot;batch&quot; of distributions.</li><li>Sample shape describes independent, identically distributed draws of batches from the distribution family.</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="examples"></a>Examples<a class="hash-link" href="#examples" title="Direct link to heading">#</a></h2><p>This is best illustrated with some simple examples. Let&#x27;s begin with a standard normal distribution:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">distributions </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> dist</span></div><div class="token-line" style="color:#393A34"><span class="token plain">d </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dist</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Normal</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loc</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> scale</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain">sample_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Output: torch.Size([]) torch.Size([]) torch.Size([])</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sample</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sample_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>In this example, we have a single scalar normal distribution from which we draw a scalar sample. Since it is a scalar distribution, the <code>event_shape = torch.Size([])</code>. Since it is a single distribution, <code>batch_shape = torch.Size([])</code>. And we draw a scalar sample since <code>sample_shape = torch.Size([])</code>.</p><p>Note that the event shape and batch shape are properties of the distribution itself, whereas the sample shape depends on the size argument passed to <a href="https://pytorch.org/docs/stable/distributions.html#torch.distributions.distribution.Distribution.sample" target="_blank" rel="noopener noreferrer"><code>Distribution.sample</code></a> or <a href="https://pytorch.org/docs/stable/distributions.html#torch.distributions.distribution.Distribution.rsample" target="_blank" rel="noopener noreferrer"><code>Distribution.rsample</code></a>. Also, the shape of <code>d.sample(sample_shape)</code> is the concatenation of the <code>sample_shape</code>, <code>batch_shape</code>, and <code>event_shape</code>, in that order.</p><p>Let&#x27;s look at another example:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain">d </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dist</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Normal</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loc</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> scale</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ones</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain">sample_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Output: torch.Size([2, 1]) torch.Size([1]) torch.Size([])</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sample</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sample_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>In this case, <code>event_shape = torch.Size([])</code> since we have a scalar distribution, but <code>batch_shape = torch.Size([1])</code> since we have tensor of parameters of that shape defining the distribution. Also, <code>sample_shape = torch.Size([2])</code> so that <code>d.sample(sample_shape).shape = torch.Size([2, 1])</code>.</p><p>A further example:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain">d </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dist</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Normal</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loc</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> scale</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ones</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain">sample_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Output: torch.Size([3, 4, 2, 5]) torch.Size([2, 5]) torch.Size([])</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sample</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sample_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>We see that batch shapes, sample shapes (and event shapes) can have an arbitrary number of dimensions are are not restricted to being vectors.</p><p>Is the event shape always <code>torch.Size([])</code>? This is not true for <em>multivariate</em> distributions, that is, distributions over vectors, matrices, and higher-order tensors that can have dependencies across their dimensions. For example:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain">d </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dist</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">MultivariateNormal</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loc</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> covariance_matrix</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">eye</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain">sample_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Output: torch.Size([3, 4, 2, 5]) torch.Size([2]) torch.Size([5])</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sample</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sample_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>Note that the <code>covariance_matrix</code> tensor will be broadcast across <code>loc</code>. <em>Whereas the previous example defined a matrix batch of scalar normal distributions, this example defines a vector batch of multivariate normal distributions.</em> This is an important distinction!</p><p>See <a href="https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/" target="_blank" rel="noopener noreferrer">this page</a> for further explanation on shape conventions.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="non-conditional-transformed-distributions"></a>Non-conditional Transformed Distributions<a class="hash-link" href="#non-conditional-transformed-distributions" title="Direct link to heading">#</a></h2><p>How do shapes work for transformed distributions that do not condition on a context variable, that is, distributions of the form <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>Î¸</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\theta(\mathbf{x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">Î¸</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span></span></span></span></span>? The sample shape depends strictly on the input to <code>.sample</code> or <code>.rsample</code> and so we restrict our attention to the batch and event shapes.</p><p>Returning to the diagram on the <a href="/users">intro page</a>, suppose the base distribution is <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">p_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, and the distribution after applying the the initial bijection, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">f_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, is <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">p_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. Denote by <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">z_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> a sample from the base distribution and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub><mo>=</mo><msub><mi>f</mi><mn>1</mn></msub><mo stretchy="false">(</mo><msub><mi>z</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">z_1=f_1(z_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>. We make a few observations:</p><p>Firstly, since <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">f_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> is a bijection, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">z_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> must have the same number of dimensions as <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">z_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. In our shape terminology, the sum of the event shape of the base distribution must be the same as the sum of the event shape of the transformed one.</p><p>Secondly, the batch shape is preserved from the base distribution to transformed one. <em>By convention, we assume that a single bijection, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">f_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, is applied to a batch of base distributions, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>p</mi><mrow><mn>0</mn><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{p_{0,i}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>, to produce a batch of the same shape of transformed distributions, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>p</mi><mrow><mn>1</mn><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{p_{1,i}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>.</em></p><p>Thirdly, the event shape of the base distribution must be compatible with the domain of the bijection. For instance, if the base distribution has event shape <code>torch.Size([])</code> and is a scalar, it does not make sense to applied a bijection on matrices with, e.g., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Dom</mtext><mo stretchy="false">[</mo><msub><mi>f</mi><mn>1</mn></msub><mo stretchy="false">]</mo><mo>âŠ†</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>Ã—</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Dom}[f_1]\subseteq \mathbb{R}^{n\times m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Dom</span></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">âŠ†</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">Ã—</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><p>Given a base distribution, <code>base</code>, and a non-conditional bijector <code>bijector</code>, the pseudo-code to calculate the batch and event shape of the transformed distribution, <code>transformed</code>, looks like this:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Input event shape must have at least as many dimensions as that which bijector operates over</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">assert</span><span class="token plain"> </span><span class="token builtin">len</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&gt;=</span><span class="token plain"> bijector</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">domain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_dim</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">transformed</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> base</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape</span></div><div class="token-line" style="color:#393A34"><span class="token plain">transformed</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> bijector</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">forward_shape</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># bijector.forward_shape and bijector.codomain.event_dim must be consistent</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">assert</span><span class="token plain"> </span><span class="token builtin">len</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">transformed</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&gt;=</span><span class="token plain"> bijector</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">codomain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_dim</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># bijectors preserve dimensions</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">assert</span><span class="token plain"> </span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">transformed</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>The <code>bijector</code> class defines the number of dimensions that it operates over in <code>bijector.domain.event_dim</code> and <code>bijector.codomain.event_dim</code>, and has a method <code>bijector.forward_shape</code> that specifies how the event shape of the input relates to that of the output. (In most cases, this will be the identity function.)</p><p>This information is sufficient to construct the batch and event shapes of the transformed distribution from the base. For a Normalizing Flow that is the composition of multiple bijections, we apply this logic in succession, using the transformed distribution of the previous step as the base distribution of the next.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="conditional-transformed-distributions"></a>Conditional Transformed Distributions<a class="hash-link" href="#conditional-transformed-distributions" title="Direct link to heading">#</a></h2><p>How do shapes work for conditional transformed distributions of the form <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>Î¸</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo>âˆ£</mo><msup><mi mathvariant="bold">z</mi><mo mathvariant="normal" lspace="0em" rspace="0em">â€²</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\theta(\mathbf{x}\mid\mathbf{z}&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">Î¸</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">âˆ£</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>? Again, we restrict our attention to the batch and event shapes. Let&#x27;s denote the base distribution of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn mathvariant="bold">0</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{z_0}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.59444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathbf mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span></span> by <code>base</code>, the transformed distribution of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn mathvariant="bold">1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{z_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.59444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathbf mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span></span> by <code>transformed</code>, and the context distribution of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">z</mi><mo mathvariant="normal" lspace="0em" rspace="0em">â€²</mo></msup></mrow><annotation encoding="application/x-tex">\mathbf{z}&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.751892em;vertical-align:0em"></span><span class="mord"><span class="mord"><span class="mord mathbf">z</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span></span></span></span></span> by <code>context</code>.</p><p>When <code>base.batch_shape = context.batch_shape = torch.Size([])</code> and, for example, <code>base.event_shape = torch.Size([10])</code>, <code>context.event_shape = torch.Size([5])</code>, clearly <code>transformed.batch_shape = torch.Size([])</code> and <code>transformed.event_shape[10]</code>. We see from this that the event shape of the context distribution should not effect the transformed one, which takes its event shape from the base.</p><p>But what about the batch shape? Suppose <code>base.batch_shape = torch.Size([1])</code>, <code>context.batch_shape = torch.Size([2])</code>, and the event shapes are as previously. Should <code>transformed.batch_shape = torch.Size([1,2])</code>, <code>transformed.batch_shape = torch.Size([2,1])</code>, <code>transformed.batch_shape = torch.Size([2])</code>, or some other possibility such as throwing an exception?</p><p><em>We define as the most sensible default that <code>transformed.batch_shape</code> is the broadcasting of <code>base.batch_shape</code> over <code>context.batch_shape</code>.</em> In this case, this means that <code>transformed.batch_shape = torch.Size([2])</code>. </p><p>We believe this makes the most sense over other design choices since we can recover the cases where <code>transformed.batch_shape</code> is the concatenation of the base and context batch sizes as a special case, e.g. when <code>base.batch_shape = torch.Size([1])</code>, <code>context.batch_shape = torch.Size([2, 1])</code>. </p><p>Pseudo-code for calculating the shapes of the transformed distribution in the conditional case looks as follows:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain">x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">empty</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain">y </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">empty</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">context</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span></div><div class="token-line" style="color:#393A34"><span class="token plain">transformed</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">y</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">transformed</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> bijector</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">forward_shape</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">event_shape</span><span class="token punctuation" style="color:#393A34">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>Of course, if the shapes cannot be broadcast over each other then an exception will be thrown.</p></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/facebookincubator/flowtorch/edit/master/website/docs/users/shapes.mdx" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" role="img" viewBox="0 0 40 40" class="iconEdit_2LL7"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/users/methods"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Table of Methods</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/users/constraints"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Constraints Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_2xL- thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#shape-conventions" class="table-of-contents__link">Shape Conventions</a></li><li><a href="#examples" class="table-of-contents__link">Examples</a></li><li><a href="#non-conditional-transformed-distributions" class="table-of-contents__link">Non-conditional Transformed Distributions</a></li><li><a href="#conditional-transformed-distributions" class="table-of-contents__link">Conditional Transformed Distributions</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Docs</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/users">Users Guide</a></li><li class="footer__item"><a class="footer__link-item" href="/dev">Developers Guide</a></li><li class="footer__item"><a class="footer__link-item" href="/api">API Reference</a></li><li class="footer__item"><a href="https://github.com/facebookincubator/flowtorch/projects" target="_blank" rel="noopener noreferrer" class="footer__link-item">Roadmap</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://github.com/facebookincubator/flowtorch/issues/new/choose" target="_blank" rel="noopener noreferrer" class="footer__link-item">Raise an issue</a></li><li class="footer__item"><a href="https://github.com/facebookincubator/flowtorch/discussions/new" target="_blank" rel="noopener noreferrer" class="footer__link-item">Ask for help</a></li><li class="footer__item"><a href="https://github.com/facebookincubator/flowtorch/discussions/categories/feedback" target="_blank" rel="noopener noreferrer" class="footer__link-item">Give us feedback</a></li><li class="footer__item"><a href="https://github.com/facebookincubator/flowtorch/fork" target="_blank" rel="noopener noreferrer" class="footer__link-item">Fork the repo</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Legal</h4><ul class="footer__items"><li class="footer__item"><a href="https://github.com/facebookincubator/flowtorch/blob/master/LICENSE.txt" target="_blank" rel="noopener noreferrer" class="footer__link-item">MIT Open Source License</a></li><li class="footer__item"><a href="https://www.contributor-covenant.org/version/1/4/code-of-conduct/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Code of Conduct</a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener" class="footer__link-item">Privacy</a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener" class="footer__link-item">Terms</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2021 Facebook, Inc. and its affiliates. All Rights Reserved.</div></div></div></footer></div>
<script src="/styles.6ecebfe1.js"></script>
<script src="/runtime~main.c1f695ac.js"></script>
<script src="/main.364a143d.js"></script>
<script src="/1.ec4b77b1.js"></script>
<script src="/2.4c431536.js"></script>
<script src="/79.187d9098.js"></script>
<script src="/81.b7c78fc7.js"></script>
<script src="/935f2afb.ab61ba57.js"></script>
<script src="/17896441.ae2496ef.js"></script>
<script src="/88d676a5.60aec92c.js"></script>
</body>
</html>